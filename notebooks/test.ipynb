{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic_ai import Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Add parent directory to Python path so we can import src\n",
    "import sys\n",
    "\n",
    "sys.path.append(os.path.abspath(\"..\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents_produced_agent = Agent[str, str](\n",
    "    model=\"openai:gpt-4o\",\n",
    "    result_type=str,\n",
    "    retries=3,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Agent' object has no attribute 'capture_run_messages'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[33]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mdocuments_produced_agent\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcapture_run_messages\u001b[49m\n",
      "\u001b[31mAttributeError\u001b[39m: 'Agent' object has no attribute 'capture_run_messages'"
     ]
    }
   ],
   "source": [
    "documents_produced_agent.capture_run_messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.utils import log_exception\n",
    "\n",
    "\n",
    "# def log_exception(\n",
    "#     job_id: str = None,\n",
    "#     model: str = None,\n",
    "#     error_message: str = None,\n",
    "#     error_category: str = None,\n",
    "#     error_traceback: str = None,\n",
    "# ) -> None:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Optional, Any, Union, get_origin, get_args\n",
    "from pydantic import BaseModel, create_model\n",
    "\n",
    "\n",
    "def create_error_model(model: Any) -> Any:\n",
    "    \"\"\"Convert all fields of a Pydantic model to Optional and adds error fields.\"\"\"\n",
    "    if not issubclass(model, BaseModel):\n",
    "        raise ValueError(\"model must be a subclass of BaseModel\")\n",
    "\n",
    "    fields = {}\n",
    "    for field_name, field in model.model_fields.items():\n",
    "        annotation = field.annotation\n",
    "        # Check if field is already optional\n",
    "        if get_origin(annotation) is not Union or type(None) not in get_args(\n",
    "            annotation\n",
    "        ):\n",
    "            fields[field_name] = (Optional[field.annotation], None)\n",
    "        else:\n",
    "            fields[field_name] = (field.annotation, None)\n",
    "\n",
    "    NewModel = create_model(\n",
    "        model.__name__ + \"Optional\",\n",
    "        __base__=model,\n",
    "        error_message=(Optional[str], None),\n",
    "        error_traceback=(Optional[str], None),\n",
    "        **fields,\n",
    "    )\n",
    "    return NewModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import functools\n",
    "import time\n",
    "import traceback\n",
    "from typing import Any, Callable, get_type_hints, cast\n",
    "\n",
    "# A generic type for functions\n",
    "F = Callable[..., Any]\n",
    "\n",
    "\n",
    "def handle_llm_errors(\n",
    "    task_name: str, error_category: str, default_message: Optional[str] = None\n",
    "):\n",
    "    \"\"\"\n",
    "    Decorator for handling errors in LLM operations.\n",
    "\n",
    "    This decorator catches exceptions, logs them, and returns a default value\n",
    "    constructed from the function's annotated return type (which must be a subclass of BaseModel\n",
    "    or a string).\n",
    "\n",
    "    Args:\n",
    "        task_name: Name of the task being performed (for logging).\n",
    "        error_category: Category of the error (for classification).\n",
    "        default_message: Default error message if none is provided.\n",
    "\n",
    "    Returns:\n",
    "        A decorator function.\n",
    "    \"\"\"\n",
    "\n",
    "    def decorator(func: F) -> F:\n",
    "        # Get type hints from the function\n",
    "        hints = get_type_hints(func)\n",
    "        return_type = hints.get(\"return\", None)\n",
    "\n",
    "        # Ensure that the return type is a subclass of pydantic.BaseModel or str\n",
    "        is_str_return = isinstance(return_type, type) and issubclass(return_type, str)\n",
    "\n",
    "        if not return_type or not (\n",
    "            is_str_return\n",
    "            or (isinstance(return_type, type) and issubclass(return_type, BaseModel))\n",
    "        ):\n",
    "            raise TypeError(\n",
    "                \"The wrapped function must have a return type annotation that is either a subclass of pydantic.BaseModel or str\"\n",
    "            )\n",
    "\n",
    "        @functools.wraps(func)\n",
    "        def wrapper(self, *args: Any, **kwargs: Any) -> Any:\n",
    "            start_time = time.perf_counter()\n",
    "            try:\n",
    "                result = func(self, *args, **kwargs)\n",
    "                # Log task completion if the logger is available\n",
    "                if hasattr(self, \"log_task_completion\"):\n",
    "                    self.log_task_completion(task_name, start_time)\n",
    "                return result\n",
    "            except Exception as e:\n",
    "                # Construct error message\n",
    "                error_message = (\n",
    "                    f\"{e}: {default_message}, \"\n",
    "                    f\"\\nCalling {func.__name__} with args: {args}, kwargs: {kwargs} \"\n",
    "                    f\"\\nStack: {traceback.format_exc()}\"\n",
    "                )\n",
    "                log_exception(\n",
    "                    job_id=getattr(self, \"job_id\", None),\n",
    "                    model=\"OpenAIModel_GPT_4O\",\n",
    "                    error_message=error_message,\n",
    "                    error_category=error_category,\n",
    "                    error_traceback=str(e),\n",
    "                )\n",
    "\n",
    "                # Handle different return types\n",
    "                if is_str_return:\n",
    "                    # For string returns, just return a friendly error message\n",
    "                    return f\"An error occurred: {error_message}. Details: {str(e)}\"\n",
    "                else:\n",
    "                    # For Pydantic models, return a default instance with added error info\n",
    "                    error_model = create_error_model(return_type)\n",
    "                    error_info = {\n",
    "                        \"error_message\": error_message,\n",
    "                        \"error_traceback\": str(e),\n",
    "                    }\n",
    "                    return error_model.model_validate(error_info)\n",
    "\n",
    "        return cast(F, wrapper)\n",
    "\n",
    "    return decorator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-02 16:33:57,350 - src.utils - ERROR - Error in job 12345, model OpenAIModel_GPT_4O, category processing_error: Simulated failure: None, \n",
      "Calling process_data with args: ('fail',), kwargs: {} \n",
      "Stack: Traceback (most recent call last):\n",
      "  File \"C:\\Users\\pdoub\\AppData\\Local\\Temp\\ipykernel_3736\\1614251534.py\", line 45, in wrapper\n",
      "    result = func(self, *args, **kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\pdoub\\AppData\\Local\\Temp\\ipykernel_3736\\2678870425.py\", line 24, in process_data\n",
      "    raise ValueError(\"Simulated failure\")\n",
      "ValueError: Simulated failure\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task process data completed in 0.00 seconds\n",
      "result='HELLO'\n",
      "result=None error_message='Simulated failure: None, \\nCalling process_data with args: (\\'fail\\',), kwargs: {} \\nStack: Traceback (most recent call last):\\n  File \"C:\\\\Users\\\\pdoub\\\\AppData\\\\Local\\\\Temp\\\\ipykernel_3736\\\\1614251534.py\", line 45, in wrapper\\n    result = func(self, *args, **kwargs)\\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \"C:\\\\Users\\\\pdoub\\\\AppData\\\\Local\\\\Temp\\\\ipykernel_3736\\\\2678870425.py\", line 24, in process_data\\n    raise ValueError(\"Simulated failure\")\\nValueError: Simulated failure\\n' error_traceback='Simulated failure'\n"
     ]
    }
   ],
   "source": [
    "# Example usage:\n",
    "\n",
    "\n",
    "class MyResponseModel(BaseModel):\n",
    "    result: Optional[str] = None\n",
    "\n",
    "\n",
    "class MyLLMClient:\n",
    "    job_id = \"12345\"\n",
    "\n",
    "    def log_task_completion(self, task_name: str, start_time: float):\n",
    "        elapsed = time.perf_counter() - start_time\n",
    "        print(f\"Task {task_name} completed in {elapsed:.2f} seconds\")\n",
    "\n",
    "    def some_log_exception(self, **kwargs):\n",
    "        print(\"Logging exception:\", kwargs)\n",
    "\n",
    "    # Simulate your log_exception function here\n",
    "    log_exception = staticmethod(lambda **kwargs: print(\"Logged:\", kwargs))\n",
    "\n",
    "    @handle_llm_errors(\"process data\", \"processing_error\")\n",
    "    def process_data(self, data: str) -> MyResponseModel:\n",
    "        # Simulate an error\n",
    "        if data == \"fail\":\n",
    "            raise ValueError(\"Simulated failure\")\n",
    "        return MyResponseModel(result=data.upper())\n",
    "\n",
    "\n",
    "# Testing\n",
    "client = MyLLMClient()\n",
    "print(client.process_data(\"hello\"))\n",
    "print(client.process_data(\"fail\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-02 16:34:35,825 - src.utils - ERROR - Error in job 12345, model OpenAIModel_GPT_4O, category processing_error: Simulated failure: None, \n",
      "Calling process_data with args: ('fail',), kwargs: {} \n",
      "Stack: Traceback (most recent call last):\n",
      "  File \"C:\\Users\\pdoub\\AppData\\Local\\Temp\\ipykernel_3736\\1614251534.py\", line 45, in wrapper\n",
      "    result = func(self, *args, **kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\pdoub\\AppData\\Local\\Temp\\ipykernel_3736\\2678870425.py\", line 24, in process_data\n",
      "    raise ValueError(\"Simulated failure\")\n",
      "ValueError: Simulated failure\n",
      "\n"
     ]
    }
   ],
   "source": [
    "t = client.process_data(\"fail\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'result': None,\n",
       " 'error_message': 'Simulated failure: None, \\nCalling process_data with args: (\\'fail\\',), kwargs: {} \\nStack: Traceback (most recent call last):\\n  File \"C:\\\\Users\\\\pdoub\\\\AppData\\\\Local\\\\Temp\\\\ipykernel_3736\\\\1614251534.py\", line 45, in wrapper\\n    result = func(self, *args, **kwargs)\\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \"C:\\\\Users\\\\pdoub\\\\AppData\\\\Local\\\\Temp\\\\ipykernel_3736\\\\2678870425.py\", line 24, in process_data\\n    raise ValueError(\"Simulated failure\")\\nValueError: Simulated failure\\n',\n",
       " 'error_traceback': 'Simulated failure'}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.model_dump()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
